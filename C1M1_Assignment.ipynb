{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a035faf8-b80f-43aa-bbdc-7a4ad5a9dd3e",
   "metadata": {},
   "source": [
    "# Programming Assignment: Deeper Regression, Smarter Features\n",
    "\n",
    "Welcome to your first assignment!\n",
    "\n",
    "You've built a solid foundation in this module, moving from simple linear models to networks that can capture complex, non-linear patterns. Now, it's time to apply those skills to a challenge that mirrors how projects work in a real-world scenario.\n",
    "\n",
    "So far, you've worked with small, manually created tensors. This time, you'll level up by loading a larger dataset from a `.csv` file, a common first step in any machine learning task. This problem is also more complex: instead of a single input predicting an outcome, you'll have **multiple features** that all work together to influence the final delivery time.\n",
    "\n",
    "This assignment also introduces you to one of the most creative and impactful parts of machine learning: **feature engineering**. You'll get to write a function that creates a completely new feature from the existing data. Designing features like this is an important skill that allows you to build more powerful and insightful models.\n",
    "\n",
    "**What You'll Do in This Assignment**\n",
    "\n",
    "* Prepare the multi-feature dataset using normalization and advanced tensor manipulations.\n",
    "* Engineer a new feature to capture more complex patterns.\n",
    "* Build a more sophisticated neural network with multiple hidden layers.\n",
    "* Train your model on the prepared data.\n",
    "* Predict a delivery time for a new, unseen order.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfe65c-a409-4bf8-a5fe-cceb4e4e0c02",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d6e80-ccce-4716-b414-914c33459715",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Imports](#0)\n",
    "- [1 - Multi-Feature Data](#1)\n",
    "    - [1.1 - Loading and Exploring the Raw Data](#1-1)\n",
    "    - [1.2 - Feature Engineering: Adding Rush Hour](#1-2)\n",
    "        - **[Exercise 1 - rush_hour_feature](#ex-1)**\n",
    "    - [1.3 - Building the Data Preparation Pipeline](#1-3)\n",
    "        - **[Exercise 2 - prepare_data](#ex-2)**\n",
    "    - [1.4 - Visualizing the Prepared Data](#1-4)\n",
    "- [2 - Building the Neural Network](#2)\n",
    "    - **[Exercise 3 - init_model](#ex-3)**\n",
    "- [3 - Training the Model](#3)\n",
    "    - **[Exercise 4 - train_model](#ex-4)**\n",
    "- [4 - Evaluating Model Performance](#4)\n",
    "- [5 - Making a New Prediction](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381cad8-2073-4fbc-a5f8-fed7d9532be3",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137c34c-6238-47e9-9513-7fc17771dd7b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.14' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/hp/.local/bin/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606497be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlai-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41bb82-26de-45ce-a8bc-50f438ab2897",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import helper_utils\n",
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2478c4-66ff-4578-bbb6-b80882f67cae",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Multi-Feature Data\n",
    "\n",
    "This time, you'll be working with a much richer dataset from a `.csv` file, containing records for **100 past deliveries**. Unlike the previous labs where time depended only on distance, this new problem is more complex. The final delivery time is now influenced by multiple input features.\n",
    "\n",
    "Here's a breakdown of the data you'll be working with:\n",
    "\n",
    "* **distance_miles**: The total distance of the delivery route in **miles**, represented as a floating point number.\n",
    "\n",
    "* **time_of_day_hours**: The time the order was **dispatched for delivery** in **hours** on a 24-hour clock, represented as a floating point number (e.g., `16.07` represents a dispatch time shortly after 4:00 PM).\n",
    "\n",
    "* **is_weekend**: A binary feature representing the day of the week, where `1` indicates a weekend and `0` indicates a weekday.\n",
    "\n",
    "* **delivery_time_minutes**: This is your **target variable**. It's the total time the delivery took in minutes, represented as a floating point number.\n",
    "\n",
    "To make the scenario more realistic, this data operates under a few business rules: **deliveries only occur between 8:00 AM (8.0) and 8:00 PM (20.0), and the company does not deliver further than 20 miles**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe75f69-2a91-4af2-87cb-afe516a07c9b",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 - Loading and Exploring the Raw Data\n",
    "\n",
    "Load and understand your data. \n",
    "\n",
    "* Define the file path to your dataset file, `./data_with_features.csv`.\n",
    "* Use Pandas library to load the dataset from the given file path as a DataFrame, `data_df`, a powerful structure for manipulating and analyzing data.\n",
    "* Inspect the shape of your data, which will show as **100 rows** (representing 100 deliveries) and **4 columns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d84ed-70a7-4797-b699-4dcc0bff6da9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset from the CSV file\n",
    "file_path = './data_with_features.csv'\n",
    "data_df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"Dataset Shape: {data_df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a21983-2503-4639-8b4e-1b13a92b441c",
   "metadata": {},
   "source": [
    "* Inspect the rows of the loaded dataset.\n",
    "    * By default, `rows_to_display` is set to `10`, but feel free to change this to a different number to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa021fc6-2209-47b2-82fc-0f8f90e5c7c3",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EDITABLE CELL:\n",
    "\n",
    "# Set the number of rows you want to display.\n",
    "rows_to_display = 10\n",
    "\n",
    "# Display the rows\n",
    "print(data_df.head(rows_to_display))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693c0c4-6c41-4f0d-9e35-97a55ada23ff",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that the data is loaded, it is time to visualize it to understand the relationships between your features and what you are trying to predict.\n",
    "\n",
    "The helper function, `plot_delivery_data` below will create a detailed scatter plot that visualizes all four features at once:\n",
    "\n",
    "* The **x-axis** will represent the **distance** of the delivery.\n",
    "* The **y-axis** will represent the **delivery time**.\n",
    "* The **color** of each point will show the **time of day**, with lighter colors for earlier dispatches and darker reds for later ones.\n",
    "* The **style** of each point will indicate the day type, with solid circles for weekdays and hollow circles for weekends.\n",
    "\n",
    "Look for patterns in the plot. Do you see how different features might be influencing the delivery time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446908a9-4764-4f72-99cf-402597e5c720",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "helper_utils.plot_delivery_data(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc2dc-3740-40c1-89c0-bfe95ea701d4",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Feature Engineering: Adding Rush Hour\n",
    "\n",
    "The visualization above reveals an interesting pattern: some deliveries take longer even for the same distance, likely due to peak traffic during **rush hours**.\n",
    "\n",
    "Instead of hoping the model learns this complex pattern on its own, you can use **feature engineering**. This is a creative step where you apply domain knowledge to make these patterns explicit. You will engineer a new feature that directly tells the model when a delivery falls within a rush hour window.\n",
    "\n",
    "> This new feature will be `1` if a delivery was dispatched during the morning rush `(8:00 - 10:00 AM)` or the evening rush `(4:00 - 7:00 PM / 16:00 - 19:00)` on a weekday, and `0` otherwise.\n",
    "\n",
    "Now, you might wonder why rush hour is only being considered on weekdays? This reflects a common real-world pattern. The concept of a \"rush hour\" is traditionally tied to weekday commuter traffic, which is the pattern that most predictably impacts delivery times on a city-wide scale. This specific pattern disappears on weekends.\n",
    "Therefore, it's a realistic assumption to make that the primary driver of rush hour delays is the weekday commute.\n",
    "\n",
    "Before applying logic to the entire dataset, it's a good practice to work with a small sample. This allows you to build and test your function quickly.\n",
    "\n",
    "* Define the first 5 rows of your `data_df` as a **PyTorch tensor**.\n",
    "* You use a tensor for this sample because your complete dataset will also be loaded as a tensor. This ensures that the function you build now will work on the full dataset later without any changes.\n",
    "* This initial tensor contains all the data for each sample delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d94e52-3b2a-40cc-8825-d5aa8dd7c45d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the 5 rows of data as a single 2D tensor\n",
    "sample_tensor = torch.tensor([\n",
    "    # distance, time_of_day, is_weekend, delivery_time\n",
    "    [1.60,      8.20,        0,          7.22],   # row 1\n",
    "    [13.09,     16.80,       1,          32.41],  # row 2       \n",
    "    [6.97,      8.02,        1,          17.47],  # row 3\n",
    "    [10.66,     16.07,       0,          37.17],  # row 4\n",
    "    [18.24,     13.47,       0,          38.36]   # row 5\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b20ab1-d425-4d18-be66-c364711f708c",
   "metadata": {},
   "source": [
    "* To create the rush feature, your calculation only depends on the **time of day** and whether it's a **weekday**.\n",
    "* Use the tensor slicing operation to select only these two columns, ignoring the unnecessary distance and delivery time data for this step.\n",
    "    * The `time_of_day_hours` is in column index `1`, and `is_weekend` is in column index `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30aab41-5ad4-462f-8b6c-238a39cfda61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use tensor slicing to separate out each column\n",
    "# Slicing syntax is [:, column_index]\n",
    "sample_hours = sample_tensor[:, 1]\n",
    "sample_weekends = sample_tensor[:, 2]\n",
    "\n",
    "print(\"--- Sliced Tensors ---\")\n",
    "print(f\"Sample Hours:    {sample_hours}\")\n",
    "print(f\"Sample Weekends: {sample_weekends}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c520139-661d-4260-a579-bb8ac20086c9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that you have the `sample_hours` and `sample_weekends` tensors prepared, you'll use them to build the `rush_hour_feature` function. \n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - rush_hour_feature\n",
    "\n",
    "Implement the `rush_hour_feature` function.\n",
    "\n",
    "**Your Task:** \n",
    "\n",
    "* **Define the individual conditions:**\n",
    "    * Define `is_morning_rush` to be `True` where the `hours_tensor` is greater than or equal to `8.0` **AND** less than `10.0`.\n",
    "    * Define `is_evening_rush` to be `True` where the `hours_tensor` is greater than or equal to `16.0` **AND** less than `19.0`.\n",
    "    * Define `is_weekday` to be `True` where the `weekends_tensor` is equal to `0`.\n",
    ">\n",
    "* **Combine the conditions:**\n",
    "    * Define `is_rush_hour_mask` by combining the three boolean tensors. The logic should be `True` only if it's a weekday **AND** it's either morning rush **OR** evening rush.\n",
    "\n",
    "**Hint**: You can use standard comparison operators (`>=`, `<`, `==`) and logical operators like `&` (AND) and `|` (OR) directly on PyTorch tensors.\n",
    "\n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "If you're stuck, think about how to build each boolean mask step by step.\n",
    "\n",
    "**For `is_morning_rush`:**\n",
    "* This requires two comparisons on the `hours_tensor` joined by a logical **AND** (`&`).\n",
    "* For example, the first part of the condition for the start of the window is `(hours_tensor >= 8.0)`. You'll need to create the second condition (`< 10.0`) and combine them.\n",
    "\n",
    "**For `is_evening_rush`:**\n",
    "* Apply the same logic as the morning rush, but for the evening time window.\n",
    "* For example, the second part of the condition for the end of the window is `(hours_tensor < 19.0)`. You'll need to create the first condition (`>= 16.0`) and combine them.\n",
    "\n",
    "**For `is_weekday`:**\n",
    "* This is a single comparison. You need to check which elements in `weekends_tensor` are equal (`==`) to `0`. The logic is: `(weekends equals 0)`.\n",
    "\n",
    "**For `is_rush_hour_mask`:**\n",
    "* This step combines the three variables you just made.\n",
    "* The logic is: `weekday AND (morning rush OR evening rush)`.\n",
    "* Remember to use parentheses `()` to group the `is_morning_rush` and `is_evening_rush` conditions together with the logical **OR** (`|`) operator.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f4807-843f-4079-ad41-4f8c691c449b",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: rush_hour_feature\n",
    "\n",
    "def rush_hour_feature(hours_tensor, weekends_tensor):\n",
    "    \"\"\"\n",
    "    Engineers a new binary feature indicating if a delivery is in a weekday rush hour.\n",
    "\n",
    "    Args:\n",
    "        hours_tensor (torch.Tensor): A tensor of delivery times of day.\n",
    "        weekends_tensor (torch.Tensor): A tensor indicating if a delivery is on a weekend.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of 0s and 1s indicating weekday rush hour.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Define rush hour and weekday conditions\n",
    "    is_morning_rush = __BLANK__\n",
    "    is_evening_rush = __BLANK__\n",
    "    is_weekday = __BLANK__\n",
    "\n",
    "    # Combine the conditions to create the final rush hour mask\n",
    "    is_rush_hour_mask = __BLANK__\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Convert the boolean mask to a float tensor to use as a numerical feature\n",
    "    return is_rush_hour_mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335f3c6-58cf-4482-9825-b4589d4e9b01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rush_hour_for_sample = rush_hour_feature(sample_hours, sample_weekends)\n",
    "\n",
    "print(f\"Sample Hours:     {sample_hours.numpy()}\")\n",
    "print(f\"Sample Weekends:  {sample_weekends.numpy()}\")\n",
    "print(f\"Is Rush Hour?:    {rush_hour_for_sample.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86feed1-b1c9-4b36-98b1-f5dd84bd77c0",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "```\n",
    "Sample Hours:     [ 8.2  16.8   8.02 16.07 13.47]\n",
    "Sample Weekends:  [0. 1. 1. 0. 0.]\n",
    "Is Rush Hour?:    [1. 0. 0. 1. 0.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060838e-93e5-4876-a9a9-69218c00cfbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_1(rush_hour_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240dd91f-d15b-4d04-8db2-83633d7a852d",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Building the Data Preparation Pipeline\n",
    "\n",
    "Now that you have your feature engineering function, you'll apply it to the data preparation pipeline. The goal is to create a single function that takes the raw pandas DataFrame as input and outputs the final `features` and `targets` tensors that your model will use for training.\n",
    "\n",
    "This function will perform several key transformations: it will call your `rush_hour_feature()` function to add the new engineered feature, normalize the `distance_miles` and `time_of_day_hours` columns so they are on a comparable scale, and handle all the necessary tensor operations to structure the data correctly.\n",
    "\n",
    "This process will yield a single `features` tensor and a single `targets` tensor, perfectly formatted for your neural network.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - prepare_data\n",
    "\n",
    "**Your Task**:\n",
    "\n",
    "Your task is to implement the core tensor manipulation steps inside the `prepare_data` function. The code for normalization and combining the final features is already provided.\n",
    "\n",
    "* **Convert DataFrame to Tensor**:\n",
    "    * Convert the `all_values` (which are extracted from the pandas DataFrame) into a single PyTorch tensor, `full_tensor`.\n",
    "    * Remember to set the `dtype` to `torch.float32`.\n",
    ">    \n",
    "* **Slice into Raw Tensors**:\n",
    "    * Use tensor slicing to separate `full_tensor` into individual 1D tensors for each column:\n",
    "        * `raw_distances` (from column index 0)\n",
    "        * `raw_hours` (from column index 1)\n",
    "        * `raw_weekends` (from column index 2)\n",
    "        * `raw_targets` (from column index 3)\n",
    ">        \n",
    "* **Create the Engineered Feature**:\n",
    "    * Call the `rush_hour_feature()` function you just built.\n",
    "    * Pass your newly sliced `raw_hours` and `raw_weekends` tensors to it.\n",
    ">    \n",
    "* **Reshape Feature Tensors**:\n",
    "    * Use the `.unsqueeze(1)` method on each of your four feature tensors (`raw_distances`, `raw_hours`, `raw_weekends`, and `is_rush_hour_feature`) to add a new dimension.\n",
    " \n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "If you need a little help, here's a more detailed guide for each step inside the function.\n",
    "\n",
    "**For `full_tensor`:**\n",
    "* You'll use the `torch.tensor()` function here.\n",
    "* The first argument should be `all_values`, and you should also set the `dtype` to `torch.float32`.\n",
    "\n",
    "**For slicing into `raw_` tensors:**\n",
    "* You'll use the slicing syntax `full_tensor[:, index]` for each variable.\n",
    "* For example, to get the `raw_distances`, the code would be `raw_distances = full_tensor[:, 0]`. Follow this pattern for the other three variables using their respective column indices.\n",
    "\n",
    "**For `is_rush_hour_feature`:**\n",
    "* This step is just a function call.\n",
    "* You need to call `rush_hour_feature()` and pass in the two tensors it needs: `raw_hours` and `raw_weekends`.\n",
    "\n",
    "**For reshaping feature tensors (e.g., `distances_col`):**\n",
    "* This is a crucial step for getting your data ready for the model.\n",
    "* For each of the four feature tensors you have (`raw_distances`, `raw_hours`, etc.), you need to call the `.unsqueeze(1)` method on it.\n",
    "* For example, the first one would be `distances_col = raw_distances.unsqueeze(1)`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757616f3-cbdd-402b-ac0f-81997989575a",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: prepare_data\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Converts a pandas DataFrame into prepared PyTorch tensors for modeling.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the raw delivery data.\n",
    "\n",
    "    Returns:\n",
    "        prepared_features (torch.Tensor): The final 2D feature tensor for the model.\n",
    "        prepared_targets (torch.Tensor): The final 2D target tensor.\n",
    "        results_dict (dict): A dictionary of intermediate tensors for testing purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the data from the DataFrame as a NumPy array\n",
    "    # (There's no direct torch.from_dataframe(), so we use .values to get a NumPy array first)\n",
    "    all_values = df.values\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Convert all the values from the DataFrame into a single PyTorch tensor\n",
    "    full_tensor = __BLANK__\n",
    "\n",
    "    # Use tensor slicing to separate out each raw column\n",
    "    raw_distances = __BLANK__\n",
    "    raw_hours = __BLANK__\n",
    "    raw_weekends = __BLANK__\n",
    "    raw_targets = __BLANK__\n",
    "\n",
    "    # Call your rush_hour_feature() function to engineer the new feature\n",
    "    is_rush_hour_feature = __BLANK__\n",
    "\n",
    "    # Use the .unsqueeze(1) method to reshape the four 1D feature tensors into 2D column vectors\n",
    "    distances_col = __BLANK__\n",
    "    hours_col = __BLANK__\n",
    "    weekends_col = __BLANK__\n",
    "    rush_hour_col = __BLANK__\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Normalize the continuous feature columns (distance and time)\n",
    "    dist_mean, dist_std = distances_col.mean(), distances_col.std()\n",
    "    hours_mean, hours_std = hours_col.mean(), hours_col.std()\n",
    " \n",
    "    distances_norm = (distances_col - dist_mean) / dist_std\n",
    "    hours_norm = (hours_col - hours_mean) / hours_std\n",
    "\n",
    "    # Combine all prepared 2D features into a single tensor\n",
    "    prepared_features = torch.cat([\n",
    "        distances_norm,\n",
    "        hours_norm,\n",
    "        weekends_col,\n",
    "        rush_hour_col\n",
    "    ], dim=1) # dim=1 concatenates them column-wise, stacking features side by side\n",
    "\n",
    "    # Prepare targets by ensuring they are the correct shape\n",
    "    prepared_targets = raw_targets.unsqueeze(1)\n",
    "    \n",
    "    # Dictionary for Testing Purposes\n",
    "    results_dict = {\n",
    "        'full_tensor': full_tensor,\n",
    "        'raw_distances': raw_distances,\n",
    "        'raw_hours': raw_hours,\n",
    "        'raw_weekends': raw_weekends,\n",
    "        'raw_targets': raw_targets,\n",
    "        'distances_col': distances_col,\n",
    "        'hours_col': hours_col,\n",
    "        'weekends_col': weekends_col,\n",
    "        'rush_hour_col': rush_hour_col\n",
    "    }\n",
    "    \n",
    "\n",
    "    return prepared_features, prepared_targets, results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be25c9-ba30-4df1-90f3-bdb55933977c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a small test DataFrame with the first 5 entries\n",
    "test_df = data_df.head(5).copy()\n",
    "\n",
    "# Print the \"Before\" state as a raw tensor\n",
    "raw_test_tensor = torch.tensor(test_df.values, dtype=torch.float32)\n",
    "print(\"--- Raw Tensor (Before Preparation) ---\\n\")\n",
    "print(f\"Shape: {raw_test_tensor.shape}\")\n",
    "print(\"Values:\\n\", raw_test_tensor)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Run the function to get the prepared \"after\" tensors\n",
    "test_features, test_targets, _ = prepare_data(test_df)\n",
    "\n",
    "# Print the \"After\" state\n",
    "print(\"--- Prepared Tensors (After Preparation) ---\")\n",
    "print(\"\\n--- Prepared Features ---\\n\")\n",
    "print(f\"Shape: {test_features.shape}\")\n",
    "print(\"Values:\\n\", test_features)\n",
    "\n",
    "print(\"\\n--- Prepared Targets ---\")\n",
    "print(f\"Shape: {test_targets.shape}\")\n",
    "print(\"Values:\\n\", test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec4361b-98c8-4834-81d5-90c6879d74fc",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "```\n",
    "--- Prepared Tensors (After Preparation) ---\n",
    "\n",
    "--- Prepared Features ---\n",
    "\n",
    "Shape: torch.Size([5, 4])\n",
    "Values:\n",
    " tensor([[-1.3562, -1.0254,  0.0000,  1.0000],\n",
    "        [ 0.4745,  1.0197,  1.0000,  0.0000],\n",
    "        [-0.5006, -1.0682,  1.0000,  0.0000],\n",
    "        [ 0.0873,  0.8461,  0.0000,  1.0000],\n",
    "        [ 1.2951,  0.2278,  0.0000,  0.0000]])\n",
    "\n",
    "--- Prepared Targets ---\n",
    "Shape: torch.Size([5, 1])\n",
    "Values:\n",
    " tensor([[ 7.2200],\n",
    "        [32.4100],\n",
    "        [17.4700],\n",
    "        [37.1700],\n",
    "        [38.3600]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e658274-1707-4a18-b353-707ba6ed208c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_2(prepare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2df178-5e08-4235-9fe7-68f1da8341a4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Excellent! As you can see from the sample results above, your `prepare_data` function successfully transformed the raw data into the two distinct tensors your model needs for training.\n",
    "\n",
    "You started with a `.csv` file containing all the data for each delivery. Your function processed this and produced:\n",
    "\n",
    "* **A \"features\" tensor**: This contains the four columns of input data (distance, time of day, weekend flag, rush hour flag) the model will learn from. Notice how the first two columns have been normalized, and the fourth column is your newly engineered `is_rush_hour` feature.\n",
    "\n",
    "* **A \"targets\" tensor**: This contains only the final `delivery_time_minutes`, separated from the input features. This is the value your model will learn to predict.\n",
    "\n",
    "Now that you have verified that your data preparation pipeline works correctly on a small sample, it's time to run it on the entire dataset to prepare all 100 delivery records for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27916a4b-243c-47f5-93b4-260944f2a81e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the entire DataFrame to get the final feature and target tensors.\n",
    "features, targets, _ = prepare_data(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff97cae-f14f-46dc-9510-a385802674c8",
   "metadata": {},
   "source": [
    "<a name='1-4'></a>\n",
    "### 1.4 - Visualizing the Prepared Data\n",
    "\n",
    "Now that your data preparation pipeline is complete, you can visualize the results to confirm your feature engineering worked as expected.\n",
    "\n",
    "#### Rush Hour Deliveries Plot\n",
    "\n",
    "* Run the cell below to display a scatter plot, showing the relationship between `Delivery Time` and `Distance`.\n",
    "* The points will be colored based on your new feature, making it easy to distinguish between \"Rush Hour\" and \"Not Rush Hour\" deliveries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec66469-e68e-4276-a4a2-bdff3d6c1c4f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "helper_utils.plot_rush_hour(data_df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afde4d-8f36-426a-a039-f116c3f25c5d",
   "metadata": {},
   "source": [
    "#### Final Prepared Data Plot\n",
    "\n",
    "* Run the cell below to display the scatter plot that visualizes the final data you will use for training your model. It will show `Delivery Time` vs. `Normalized Distance`.\n",
    "* The points are styled by four categories, combining the day type and your new rush hour feature.\n",
    "* Note that \"Weekend (Rush Hour)\" does not appear, as your feature correctly applies only to weekdays (as explained above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945660b2-07be-4a5c-900f-c64e2a190d13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "helper_utils.plot_final_data(features, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec7bf40-a104-46f9-8120-5af7b142492b",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Building the Neural Network\n",
    "\n",
    "With your data pipeline complete, you are now ready for the next major stage: **building the model.**\n",
    "\n",
    "Since your problem now involves multiple features, you'll need a more sophisticated architecture than the ones you had seen before. You will build a neural network with two hidden layers to capture the complex relationships between all your input features.\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - init_model\n",
    "\n",
    "Implement the `init_model` function, to define the model architecture, the optimizer, and the loss function.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "* **Define the Model Architecture**:\n",
    "    * Define a `model` using `nn.Sequential`.\n",
    "    * The model **should only** have three `nn.Linear` layers, each followed by a `nn.ReLU()` activation function, except for the last one.\n",
    "        * **Input Layer**: An `nn.Linear` layer that accepts **4 input features** and outputs **64 features**.\n",
    "        * **Hidden Layer**: An `nn.Linear` layer that takes the **64 features** from the previous layer and outputs **32 features**.\n",
    "        * **Output Layer**: A final `nn.Linear` layer that takes the **32 features** from the hidden layer and produces a **single output** value.\n",
    ">        \n",
    "* **Define the Optimizer**:\n",
    "    * Define the `optimizer` as **Stochastic Gradient Descent (SGD)**. You need to pass it the model's parameters (`model.parameters()`) and set the learning rate (`lr`) to `0.01`.\n",
    ">\n",
    "* **Define the Loss Function**:\n",
    "    * Define the `loss_function` as **Mean Squared Error (MSE)**.\n",
    " \n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "**For the Model:**\n",
    "* Remember to list your layers inside the `nn.Sequential()` constructor, separated by commas.\n",
    "* The `nn.Linear()` layer takes two main arguments: `in_features` and `out_features`. Ensure the `in_features` of one layer matches the `out_features` of the one before it.\n",
    "* The correct order of layers is: **Input Layer -> ReLU -> Hidden Layer -> ReLU -> Output Layer.**\n",
    "\n",
    "**For the Optimizer:**\n",
    "* You will use `optim.SGD`. Its first argument is the model's parameters, which you can get with `model.parameters()`.\n",
    "* The second argument you need to provide is the learning rate, `lr=0.01`.\n",
    "\n",
    "**For the Loss Function:**\n",
    "* You will use `nn.MSELoss`. Since it is a class, you need to create an instance of it by calling it with parentheses: `nn.MSELoss()`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c476923-539d-411a-a040-20099bb4198a",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: init_model\n",
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    Initializes the neural network model, optimizer, and loss function.\n",
    "\n",
    "    Returns:\n",
    "        model (nn.Sequential): The initialized PyTorch sequential model.\n",
    "        optimizer (torch.optim.Optimizer): The initialized optimizer for training.\n",
    "        loss_function: The initialized loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the random seed for reproducibility of results (DON'T MANIPULATE IT)\n",
    "    torch.manual_seed(41)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the model architecture using nn.Sequential\n",
    "    model = __BLANK__\n",
    "        # Input layer (Linear): 4 input features, 64 output features\n",
    "        __BLANK__\n",
    "        # First ReLU activation function\n",
    "        __BLANK__\n",
    "        # Hidden layer (Linear): 64 inputs, 32 outputs\n",
    "        __BLANK__\n",
    "        # Second ReLU activation function\n",
    "        __BLANK__\n",
    "        # Output layer (Linear): 32 inputs, 1 output (the prediction)\n",
    "        __BLANK__\n",
    "        __BLANK__\n",
    "    \n",
    "    # Define the optimizer (Stochastic Gradient Descent)\n",
    "    optimizer = __BLANK__\n",
    "\n",
    "    # Define the loss function (Mean Squared Error for regression)\n",
    "    loss_function = __BLANK__\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return model, optimizer, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14c137-33aa-4d17-9970-82ce69b6b430",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, optimizer, loss_function = init_model()\n",
    "\n",
    "print(f\"{'='*30}\\nInitialized Model Architecture\\n{'='*30}\\n{model}\")\n",
    "print(f\"\\n{'='*30}\\nOptimizer\\n{'='*30}\\n{optimizer}\")\n",
    "print(f\"\\n{'='*30}\\nLoss Function\\n{'='*30}\\n{loss_function}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250b262-ce83-469a-aa81-4205c6034121",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "==============================\n",
    "Initialized Model Architecture\n",
    "==============================\n",
    "Sequential(\n",
    "  (0): Linear(in_features=4, out_features=64, bias=True)\n",
    "  (1): ReLU()\n",
    "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
    "  (3): ReLU()\n",
    "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
    ")\n",
    "\n",
    "==============================\n",
    "Optimizer\n",
    "==============================\n",
    "SGD (\n",
    "Parameter Group 0\n",
    "    dampening: 0\n",
    "    differentiable: False\n",
    "    foreach: None\n",
    "    fused: None\n",
    "    lr: 0.01\n",
    "    maximize: False\n",
    "    momentum: 0\n",
    "    nesterov: False\n",
    "    weight_decay: 0\n",
    ")\n",
    "\n",
    "==============================\n",
    "Loss Function\n",
    "==============================\n",
    "MSELoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6eae0-a524-4ddf-b45e-ca3daf23a27b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_3(init_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71422b4b-2cbc-45aa-9a91-e1ee7117bfb7",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Training the Model\n",
    "\n",
    "With your data prepared and your model architecture defined, it's time for the most important stage: **training**. \n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Exercise 4 - train_model\n",
    "\n",
    "Implement the complete training loop inside the `train_model` function.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "* **Initialize your model and tools:**\n",
    "    * Start by calling the `init_model()` function you built earlier to get your `model`, `optimizer`, and `loss_function`.\n",
    ">    \n",
    "* **Loop through the epochs:**\n",
    "    * Create a `for` loop that iterates from 0 up to the number of `epochs` provided.\n",
    ">    \n",
    "* **Implement the training steps inside the loop:**\n",
    "    * Perform these five steps **in order** on each iteration:\n",
    "        * **Forward Pass**: Pass your `features` tensor into the `model` to get its predictions.\n",
    "        * **Calculate Loss**: Use your `loss_function` to compare the model's predictions with the actual `targets`.\n",
    "        * **Zero Gradients**: Zero the gradients on the `optimizer` from the previous iteration.\n",
    "        * **Backward Pass**: Perform the backward pass on your `loss` to calculate the new gradients.\n",
    "        * **Update Weights**: Take a step with the `optimizer` to update the model's parameters.\n",
    " \n",
    "<details>\n",
    "  <summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "  \n",
    "**For Initialization:**\n",
    "* The `init_model()` function returns three values. You can unpack them directly into your three variables: `model, optimizer, loss_function = init_model()`.\n",
    "\n",
    "**For the Forward Pass:**\n",
    "* To get predictions, you can call your `model` object like a \"function\", passing the `features` as the \"argument\", `function(argument)`.\n",
    "\n",
    "**For Calculating Loss:**\n",
    "* The loss function also works like a function. It takes two arguments, your \"predictions\" and \"actual targets\".\n",
    "\n",
    "**For the Gradient Steps:**\n",
    "* The three gradient-related steps (`.zero_grad()`, `.backward()`, and `.step()`) are all methods that need to be called with parentheses, for example, `optimizer.zero_grad()`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8e58b-b711-462e-9db9-26a8d3d1ca1c",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_model\n",
    "\n",
    "def train_model(features, targets, epochs, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains the model using the provided data for a number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        features (torch.Tensor): The input features for training.\n",
    "        targets (torch.Tensor): The target values for training.\n",
    "        epochs (int): The number of training epochs.\n",
    "        verbose (bool): If True, prints training progress. Defaults to True.\n",
    "        \n",
    "    Returns:\n",
    "        model (nn.Sequential): The trained model.\n",
    "        losses (list): A list of loss values recorded every 5000 epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to store the loss\n",
    "    losses = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Initialize the model, optimizer, and loss function using `init_model`\n",
    "    model, optimizer, loss_function = __BLANK__\n",
    "\n",
    "    # Loop through the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Forward pass: Make predictions\n",
    "        outputs = __BLANK__\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = __BLANK__\n",
    "\n",
    "        # Zero the gradients\n",
    "        __BLANK__\n",
    "\n",
    "        # Backward pass: Compute gradients\n",
    "        __BLANK__\n",
    "\n",
    "        # Update the model's parameters\n",
    "        __BLANK__\n",
    "    \n",
    "    ### END CODE HERE ### \n",
    "\n",
    "        # Every 5000 epochs, record the loss and print the progress\n",
    "        if (epoch + 1) % 5000 == 0:\n",
    "            losses.append(loss.item())\n",
    "            if verbose:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde461db-5507-4103-ad2d-e07517feb30e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model, loss = train_model(features, targets, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b6ca0-35a0-413d-936f-78c566d82c10",
   "metadata": {},
   "source": [
    "#### Expected Output (approximately):\n",
    "\n",
    "```\n",
    "Epoch [5000/10000], Loss: 3.0901\n",
    "Epoch [10000/10000], Loss: 1.6064\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219224ac-0f14-4767-ad0b-bb8e9f3b990e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_4(train_model, features, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa9c08-d560-4eb2-9865-1d9b48e7b140",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "# Congratulations!\n",
    "\n",
    "You've completed the final graded exercise of this assignment.\n",
    "\n",
    "If you've successfully passed all the unit tests above, you've completed the core requirements of this assignment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aadd33-558a-4dc2-9089-bae34b157add",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "It's time to put your `train_model` function to work. Run the complete training on the `features` and `targets`. You will train the model for `30,000` epochs (more than the test run to ensure full convergence on the complete dataset), which gives it ample opportunity to learn the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b467024-3b80-4136-ab2e-38c1f70ffc9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model, loss = train_model(features, targets, 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f683c-0b59-471c-bc9b-8855595d294c",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Evaluating Model Performance\n",
    "\n",
    "Now that your model is trained, it's time to evaluate its performance. A simple yet powerful way to do this for a regression task is to plot the model's predictions against the actual target values.\n",
    "\n",
    "* First, use your trained `model` to get predictions for the entire dataset.\n",
    "* Then, create a scatter plot, **Actual Delivery Times (x-axis) vs. Predicted Delivery Times (y-axis)**.\n",
    "* If the model is accurate, the points on the plot should form a tight cluster along a straight diagonal line.\n",
    "    * The closer the points are to this line, the better your model's predictions are.\n",
    "    \n",
    "Let's see how well your model did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913363e4-71e4-4aa5-bde1-a225995a08cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable gradient calculation for efficient predictions\n",
    "with torch.no_grad():\n",
    "    # Perform a forward pass to get model predictions\n",
    "    predicted_outputs = model(features)\n",
    "\n",
    "# Plot predictions vs. actual targets to evaluate performance\n",
    "helper_utils.plot_model_predictions(predicted_outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4454f-9439-44bc-9755-f2e5a6221c5e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The results look fantastic!\n",
    "\n",
    "As you can see in the \"Actual vs. Predicted\" plot, the model's predictions (the light gray points) form a very tight cluster that follows the \"Perfect Prediction\" line almost exactly. This indicates that your model has learned the patterns in the data very well and is making highly accurate predictions.\n",
    "\n",
    "A result like this in a real-world project would be considered a great success. With your model's performance evaluated, you're ready for the final step: using it to make a prediction on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00479ca8-3afb-46f1-a4fd-4326bcdb5d4d",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Making a New Prediction\n",
    "\n",
    "With a well-trained and evaluated model, you've reached the final and most practical stage: **prediction**. It's time to use your model to make a prediction on new, unseen data. \n",
    "\n",
    "* Define a new delivery scenario by setting the distance, time of day, and whether it's a weekend.\n",
    "\n",
    "**Note on Business Rules:**\n",
    "Remember the constraints of the delivery service when setting your values:\n",
    "* **Distance**: Must be less than or equal to `20` miles.\n",
    "* **Time**: Must be between `8.0` (8:00 AM) and `20.0` (8:00 PM).\n",
    "* **Weekend**: Can be set using `True`/`False` or `1`/`0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d52901-e22b-421b-bbcc-a329bb233107",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EDITABLE CELL: Set your values below\n",
    "\n",
    "# Change the values below to get an estimate for a different delivery\n",
    "# Set distance for the delivery in miles\n",
    "distance_miles = 20.0 \n",
    "# Set time of day in 24-hour format (e.g., 9.5 for 9:30 AM)\n",
    "time_of_day_hours = 10.0\n",
    "# Use True/False or 1/0 to indicate if it's a weekend\n",
    "is_weekend = 1.0\n",
    "\n",
    "# Convert the raw inputs into a 2D tensor for the model\n",
    "raw_input_tensor = torch.tensor([[distance_miles, time_of_day_hours, is_weekend]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15846f5-9961-47a7-bc8f-8dbb1fce31aa",
   "metadata": {},
   "source": [
    "Now, you'll pass your trained `model`, the original `data_df`, your `raw_input_tensor`, and the `rush_hour_feature` function to the helper function. This will process your new inputs and use the model to generate the estimated delivery time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc4676-0b55-4d78-a7cf-e5adc7ccae8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "helper_utils.prediction(model, data_df, raw_input_tensor, rush_hour_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced53bb-97ba-47a7-9059-4d1da8540b23",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on completing your first assignment!\n",
    "\n",
    "You have successfully navigated every key stage of the pipeline. You started with raw data from a `.csv` file, performed **feature engineering** to add business logic to your dataset, and built a complete **data preparation pipeline** to automate the process.\n",
    "\n",
    "From there, you designed and **trained** a multi-layer neural network, moving beyond the simple models of the ungraded labs. You then **evaluated** its performance by visualizing its predictions and, finally, used your trained model to make a **prediction** on new, unseen data.\n",
    "\n",
    "The skills you've practiced here on manipulating tensors, designing features, and building end-to-end training pipelines are the fundamental building blocks for tackling even more complex challenges in deep learning. You now have a solid foundation to build upon as you move forward. Well done!"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
